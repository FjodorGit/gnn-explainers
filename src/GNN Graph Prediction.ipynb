{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "db87ecdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "\n",
    "from torch_geometric.datasets import ExplainerDataset, BA2MotifDataset, TUDataset\n",
    "from torch_geometric.datasets.graph_generator import BAGraph\n",
    "from torch_geometric.explain import Explainer, GNNExplainer, PGExplainer, DummyExplainer\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "from torch_geometric.utils import to_networkx\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GCNConv, Linear, global_mean_pool, GraphConv\n",
    "from torch_geometric.explain.metric import fidelity, unfaithfulness\n",
    "\n",
    "from torch_geometric.utils import scatter\n",
    "\n",
    "torch_geometric.seed_everything(41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a97e0e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "train_dataset = dataset[:int(len(dataset) * 0.8)]\n",
    "test_dataset = dataset[int(len(dataset) * 0.2):]\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1f120b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 42], x=[19, 7], edge_attr=[42, 4], y=[1])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgQAAAGFCAYAAACCBut2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABRQklEQVR4nO3de1xUdf4/8Nc5M4KAgDIIijIgckkRRQ1RlAzv3Sy10lL71ep2tTZb3cytvLSpbe7ablpft5ulltWummmZUqgYgnhHvAAiDIpKzCi30cG5/P4gJgmU2zlzYV7Pf3o458zn85kUzns+l/dbsFgsFhAREZFLE+09ACIiIrI/BgRERETEgICIiIgYEBAREREYEBAREREYEBAREREYEBAREREAZVNuMpvNKC4uhre3NwRBkHtMREREJAGLxYKKigoEBQVBFG89B9CkgKC4uBjBwcGSDI6IiIhsq6ioCN27d7/lPU0KCLy9va0N+vj4tH5kREREJLvy8nIEBwdbn+O30qSAoHaZwMfHhwEBERGRk2nKcj83FRIREREDAiIiImJAQERERGBAQERERGBAQERERGBAQERERGBAQERERGBAQERERGBAQERERGBAQERERGBAQERERGBAQERERGBAQERERGBAQERERGBAQERERGBAQERERACU9h4AkaupMhhRoK1CtdEMN6WIUJUXvNz5o0hE9sXfQkQ2kHupAuszNEg5XQKNTg/LDdcEAGo/TyRFBWBqvBoRgd72GiYRuTDBYrFYGrupvLwcvr6+KCsrg4+Pjy3GRdQmFOn0mL8pC6l5pVCIAkzmm/+41V5PDPfHkgkxCPbztOFIiagtas7zm3sIiGSyIVODUSt2Iy1fCwC3DAZuvJ6Wr8WoFbuxIVMj+xiJiGpxyYBIBitTcrF8R06L3msyW2AyWzBvYxZKKw2YlRQh8eiIiOrjDAGRxDZkalocDPze8h05+JIzBURkAwwIiCRUpNNjwZZsSdt8fUs2inR6SdskIvo9BgREEpq/KQvGRvYKNJfRbMH8TVmStklE9HsMCIgkknupAql5pY1uHmwuk9mC1LxS5JVUSNouEdGNGBAQSWR9hgYKUZClbYUoYF069xIQkXwYEBBJJOV0ieSzA7VMZgtSckpkaZuICOCxQyJJVBqM0Mi88U+j1aPKYGSaY5kwpTS5Ov5rJ5JAobYK8swN/MYCoEBbheggX5l7ch1MKU30GwYERBKoNprbVD9tXVNSSlsAFOr0WJtRiDX7CphSmto87iEgkoCb0jY/Srbqpy1jSmmihnGGgEgCoSovCICsywbCr/1QyzGlNNHN8esGkQS83JVQyzyVrFZ5cpNbKzClNNGtMSAgkkhSVICseQiSIgNkadsVMKU0UeMYEBBJZGq8WtY8BNMGq2Vp2xUwpTRR4xgQEEkkItAbieH+ks8SKEQBieH+CA/gsbeWYEppoqZhQEAkoSUTYqCUOCBQigKWTIiRtE1XwpTSRE3DgIBIQsF+nlg0PlrSNhePj+bZ91ZgSmmipmFAQCSxKXFqzBkTKUlbc8dEYXIc9w60lC1TShM5OwYERDKYlRSBZRNj4K4Umz1dLcICd6WItybG4LmkcJlG2DZUV1fj66+/RmFhYYPXbZlSmsjZMSAgksmUODWSZw9HQpgKABoNDCxmEwCgp7cZybOHc2agCY4ePYqHH34YoaGh6Nu3L9544w0cP34cFktNGMCU0kRNJ1hqf3Juoby8HL6+vigrK4OPj48txkXUpliL6OSUQKOtX0Snk5sJhfu+R/mhrXh47B1Yv3699Tqr8N1cSUkJAgMDrX8WBAEWiwWenp4IDAxEt+h4FPWZJvs4tj0/jEWnyCE15/nN3ypENhAR6I2F46OxENE3fcAvXZqN+TvP4fPPP4d7QCi6DZ+CPbmlrML3O3q9Hj/99BNSU1Nx6NAhaxAAwPpfvV6PwsJC9I8bjCKZx8OU0tRWMCAgsjEvd2WD3yajo6Oh9A2E37jn8FP7AcC+s4CoqHefq1ThKy4uxs6dO5GWloasrCwUFBRAq9Wiurraeo8gCHUCglpPPPEE3n33XXh5eWH42ykolHFjIVNKU1vBf8VEDuLnCxZ0nfkehNogoIFg4Ea/r8K3aHw0pjjZvgOz2Yzjx48jOTkZ+/fvx8mTJ3Hu3DmUlZXBZDJZ71MoFPD19UWvXr3Qq1cvxMfHY9SoUejduzeefPJJfPLJJxBFEV5eXvjkk08wYcIE63uTogKwNqNQlqOHTClNbQkDAiIHsDIlF18WKCEoFRCE5p1KcIYqfNXV1UhNTcWuXbtw6NAh5Obm4sKFC6iqqqrz7d7NzQ0qlQrx8fGIiYlBQkICRo0ahaCgoJu23bt3b5jNZiQmJmL9+vXo1q1bnetT49VYs69Als/FlNLUljAgILKzG6vwNTcY+L3lO3LQuYO73U4o6HQ67Ny5E3v37sWxY8eQn5+PX375BQaDoc59Xl5eCAwMRHh4OPr374877rgDd955Jzw9m7/sMXPmTPTo0QP3338/RLH+wanalNJp+VpJZwkUooCEMBVTSlObwVMGRHZUpNNj1IrdMEh4bM1dKSJ59vAG9xRYLBZYLJYGH5zNcfr0afz4449IT09HdnY2ioqKcPnyZRiNvyXoEUURPj4+6NatG2677TYMGjQISUlJGDhwYKv7by5b/38mchQ8ZUDkJOSswrd2Rnyd1/ft24cpU6bg3nvvxapVqxpvx2hEeno6du3ahQMHDuD06dMoLi5GRUVFnWn+du3awc/PD/3790efPn2s0/yhoaGSfq7WqE0pPW+jdNUJmVKa2hoGBER2UluFT2o3VuELD/CG0WjEkiVLsGjRIpjNZuzatavO/eXl5fjxxx+xd+9eHDlyBGfOnEFJSQmuXr1a5z4PDw8EBARg4MCBiI2NRWJiIkaMGAFfX+c4fz8lTo3SSoN1eaY1mFKa2iIGBER2UluFT67d7+vSNXiiXwdMmTIFGRkZ1m/1p06dwqBBg6DRaKDT6XD9+nXr+wRBgLe3N0JCQhAZGYmBAwdixIgRGDx4MJRK5/91MSspAv4d3LFgSzaMv27GbCqFKEApClg8PprBALVJ3ENAZCdyn493qy7DmXemw2yuv26uUCjQqVMnqNVqREdHY9CgQRg9ejSioqJkG48jKdLpMX9TFlLzShsNymqvt9V8D9S2cQ8BkYOzRRU+QzsfWBRugPlavWtbtmzB3XffLWv/jizYzxNrZ8Q3mlJarfJEUmQApg1W8zQBtXkMCIjswBZV+ARBwPafD+J46nb897//RXp6unXZ4OTJky4dENRqSkppIlfBf+1EdmCr6nidA7vipZdewksvvYRLly5hy5Yt+P7779G/f3+b9O9MbpZSmshVMCAgsgM3pW3O4d/YT2BgIP74xz/ij3/8o036JiLnYtvsIEQEoKY6XutyEjaOVfiIqDkYEBDZgZe7EmqZd6uzCh8RNQcDAiI7SYoKgEKUZ56AVfiIqLkYEBDZyaTYQFmSEgGswkdEzcf5RCKZXb16FTqdDlqtFlqtFqWlpVi7di32798P1YMLcM03hFX4iMjuGBAQySg8PBxnzpxp8FpoaCg+fHIkHv/6jKQBgVIUsGRCjGTtEZFr4JIBkYx69OjR4Ot+fn44deoUhvSNxKLx0ZL2ySp8RNQSDAiIZPTOO+9AEOpvHNyyZQvc3d0B1FThmzMmUpL+WIWPiFqKAQGRTL744gsMGTIEN9YPE0URzzzzDIYOHVrn3llJEVg2MQbuSrHZJw8UogB3pYi3JsbguaRwScZORK6HAQGRxM6cOYM+ffrg0UcfRXV1NZYsWYKAgJojgAEBAVi2bFmD75sSp0by7OFICFMBQKOBQe31hDAVkmcP58wAEbUKNxUSSaS6uhp/+MMf8Pnnn8NiseCBBx7A+vXr4enpiZ49e+KRRx7Bhx9+eMsSpKzCR0T2IlhunM+8iebUUyZyRR9++CH+9Kc/Qa/Xo2fPnti0aRNiYuru9NdqtVCpVM1um1X4iKilmvP85m8VolbIzs7GhAkTkJubCw8PD6xevRpPPvlkg/e2JBgAWIWPiGyDAQFRC1y7dg1Tp07Fxo0bIQgCHn30UXzyySdwc3Oz99CIiFqEmwqJmulf//oXOnXqhI0bN6JXr144deoU1q9fz2CAiJwaZwiImujAgQN48MEHUVhYiA4dOmDt2rWYNm2avYdFRCQJzhAQNaKyshJ333034uLioNFoMGPGDFy+fJnBABG1KQwIiG5h6dKl8PPzw/fff4/Y2FicPXsWH374IZRKTq4RUdvC32rk8iwWS730wnv37sXDDz+MCxcuwNfXFx9//DEmTpxopxESEcmPMwTk1KoMRmQXl+Gw5jKyi8tQZTA26/2vvPIKEhISYDTWvE+n02HEiBFITEzEpUuX8MILL0Cn0zEYIKI2jzME5HSsWfxOl0CjayCLn58nkqICMDVejYjAm2fxS0tLw1tvvQWLxYJVq1ahpKQEf//732E0GhEfH4/NmzejS5cusn8eIiJHwEyF5DSKdHrM35SF1LxSKEQBJvPN/+nWXk8M98eSCTH1ygEbDAbExMQgPz8fJpPJ+rpKpcLatWtx1113yfY5iIhspTnPby4ZkFPYkKnBqBW7kZavBYBbBgM3Xk/L12LUit3YkKmpc33JkiXIy8urEwzExMSgpKSEwQARuSQGBOTwVqbkYt7GLBiM5kYDgd8zmS0wGM2YtzELK1NyAQDHjh3DG2+8gd9PjmVlZWH//v2SjZuIyJkwICCHtiFTg+U7ciRpa/mOHKz4JgNxcXH1goFa//vf/yTpi4jI2XBTITmsIp0eC7ZkS9rmO6nn4dk5GHGhXXD33XdDpVLBz88PKpUKKpUKvXr1krQ/IiJnwYCAHNb8TVkwNnOJoDGKdu64e8FarP/jEEnbJSJydlwyIIeUe6kCqXmlzd4z0BgzgJ/zdcgrqZC0XSIiZ8eAgBzS+gwNFKLQ+I0toBAFrEvXNH4jEZELYUBADinldInkswO1TGYLUnJKZGmbiMhZMSAgh1NpMEKj08vah0arb3aaYyKitowBATmcQm0V5Jkb+I0FQIG2SuZeiIicB08ZkF0888wzuHTpEsaOHYsxY8agR48e1mvVRrNNxmCrfoiInAEDArKL9PR0HDlyBJs3b4bFYkFISAjGjRuHwMBAtO8SDsBP9jG4KTlBRkRUiwEB2cXAgQNx7NgxmM0139ILCwuxevVqAIDQrj3UL30NCPKcMgBqqiKGqrxka5+IyNnwKxLJ7tq1a9i4cSNmzpyJfv36wcfHBx999JE1GLjRkCFDcL4wHyEyP6zVKk94uTMeJiKqxd+IJKlr165h27Zt+O6775CZmYmzZ8+isrLSer1du3YICgpCbGwsUlNTAQAKhQJKpRIffPABpk+fDgBIitJhbUahLEcPFaKApMgAydslInJmDAioxfR6PbZu3Yrvv/8eBw4cQEFBQZ2Hv5ubG7p27YoRI0ZgxIgRmDRpErp37w4AqK6uhpeXF4xGI4KDg/HNN9+gb9++1vdOjVdjzb4CWcZtMlswbbBalraJiJwVAwIJVBmMKNBWodpohptSRKjKq81NR+v1enz77bd1Hv5VVb8d23Nzc0NQUBBGjhyJkSNHYtKkSQgKCrppe25ubrjvvvsgiiI+/PBDdOzYsc71iEBvJIb7Iy1fK+ksgUIUkBCmQniAt2RtEhG1BYLlZnVgb1BeXg5fX1+UlZXBx8fHFuNyeLmXKrA+Q4OU0yXQ6PR1zs0LANR+nkiKCsDUeDUiAp3r4VNZWYlvv/0W27dvx4EDB1BYWFjv4d+tWzf069cPI0eOxMSJE2/58G+pIp0eo1bshkHC44HuShHJs4cj2M9TsjaJiBxVc57fDAiaqUinx/xNWUjNK4VCFG757bX2emK4P5ZMiHHIh1BlZSW++eYb/PDDD9aHv17/W5ZAd3d368N/1KhRmDhxIrp06WKz8W3I1GDexizJ2ntrYgwmx3G5gIhcQ3Oe321rXltmGzI1WLAl21qSt7Gp7NrraflajFqxG4vGR2OKHR9GFRUV+Oabb7B9+3YcPHgQGo2mwYd/bGwsRo0ahUmTJiEgwL6b76bEqVFaacDyHTktbsNisUAQBMwdE8VggIjoJhgQNNHKlNwWP5RMZgtMZgvmbcxCaaUBs5IiJB5dfeXl5di8eTN++OEHHDp0CIWFhbh69ar1uru7O7p3747Y2FiMHj0aEyZMsPvD/2ZmJUXAv4O7NRhrzp4ChSjAbDSi9PtVWL3tIhI+/RT9+/eXcbRERM6JSwZNYMtp67y8PAQHB8Pd3b3J7ZWVldV5+Gs0mjoP//bt29d5+E+cOBH+/v6t/hy21tLlmpmxHXDn7X2s18aMGYPXX38dQ4cOtcWwiYjshnsIJGSrjW1msxlvvPEGFi1ahGXLluEvf/lLg++9cuUKNm3ahB07duDQoUMoKiqq9/APDg5GbGwsxowZgwkTJkClUkk2dkdg3dCZUwKNtoENnSpPJEUGYNpgNcIDvGGxWODr64uKigoANXkPTCYThg0bhlWrVtU57khE1JYwIJDQ9I8yZDv6tnZGPABAp9PhkUcewY4dOwAA999/PzZv3ozLly9j48aN2Llzp/Xhf+3aNWs7tQ//AQMGWKf9/fzkrwHgSJp65HP06NFITk6u9/pDDz2E999/v80FTUREADcVSib3UgVS80olb9dktiA1rxR5JRUoP5eL+++/HxcuXLBe37p1Kzw8POo8/D08PKBWqzFgwADrN//fn913RV7uSkQH+TZ6X1xcHHbt2gWj0Wh9rVevXvj666/Rs2dPLF26VM5hEhE5PAYEt7A+Q9PoWnVLiQLw0Cvv4sjHf613zWQyITQ0FIMGDcLYsWNx//338+HfSgMGDIDRaLQuFwDAqVOnAAD79++359CIiBwCA4JbSDldIkswAABmC1Ci7Gz9syAIuHH15t1338Vdd90lS9+uKC4uDgDQpUsXlJaWwmAwWP9/HzhwwHo0kYjIVbHa4U1UGozQ6PSN39gKbn5BOJF7Bh988AEmTZoEb+/fMhoeO3ZM1r5dTUhICD7//HOcP38eBoOhzrXy8nJoNBo7jYyIyDFwhuAmCrVVkGdu4DcWAGZPFWbOnImZM2fCZDLh4MGD2L17N8aPHy9z767n4YcfRl5eHpYvX46Kioo6MzIHDx5ESEhIvfe4Qp0KIiKApwxu6rDmMia8nyZ7P5ueSUB/dSfZ+6HfVFRUYPXq1Vi2bBm0Wi0A4O6778a2bdsAtO06FUTkWnjsUALZxWW45929svez7flhTdolT9K7evUq3nvvPcydOxft2rVDRvYZ/GP3+TZTp4KIqDnPb+4huIlQlRfk3mIm/NoP2YeHhwf+/Oc/o7CwEH5x92HSR4eRll8zY9DcOhUbMrkHgYicGwOCm/ByV0It87c+tcqT69EO4Ju8a3BPfAImiM0+VWIyW2AwmjFvYxZWpuTKNEIiIvkxILiFpKgAKER55gkUooCkSMcsJuRKNmRqWlVJ8UbLd+TgS84UEJGTYkBwC1Pj1bLlITCZLZg2mKV47alIp8eCLdmStvn6lmwUyXxclYhIDgwIbiEi0BuJ4f6SzxIoRAGJ4f4ID+AOdXuavykLRokDPqPZgvmbpKuMSURkKwwIGrFkQgyUEv9fUooClkyIkbZRapbaOhVSzwDdWKeCiMiZMCBoRH5WJqr2rJG0zcXjo3lMzc5q61TIQSEKWJfOvQRE5FwYEDTg4sWLeO+999CnTx/ceeed0GVuxVNDgiRpe+6YKEyO494Be5OzToXJbEFKToksbRMRyYVn3n5VUVGB9evX44svvkBqamqdtLYLFizAy+P7o0dXFRZsyYbRbGnWw0QhClCKAhaPj2Yw4ABsUadCo9WjymDksVIichr8bfWr5cuXY/HixfWqDiqVSjz77LMAgClxagzt6Y/5m7Kalc0uIUzFbHYOxFZ1Kgq0VcxCSUROgwHBr55//nl8/fXXOH36tDUgEEURd999d50qhMF+nlg7I/63fPc5JdBoG8h3r/JEUmQApg1W8zSBg6k2mttUP0REUnDpgODq1at46aWX8Mwzz6Bv37548803MXHiROt1s9mMhx9+uMH3RgR6Y+H4aCxENCviORk3qY+N2LkfIiIpuPRvrG+//Rb/93//h+HDh+ODDz7AQw89hHbt2qFnz54AgHbt2uG+++5rtB0vdyWig3zRX90J0UG+DAYcHOtUEBHV59JPrq+//hoKhQLl5eV48sknoVQqkZ6ejpCQEIwcORK9e/d2meqOrqS2TkWhjBsLWaeCiJxNm/qN1Zype71ej61bt8JkMllfa9++PRQKBVQqFQ4fPgyzmWvAbVVSVADWZhTKcvSQdSqIyBk5fUBg3dx3ugQaXQOb+/w8kRQVgKnxakQE/ra577vvvsO1a9fqtFVZWYnhw4dDo9HAx8cHCoXCNh+CbG5qvBpr9hXI0jbrVBCRM3LagKBIp2/0+J8FQKFOj7UZhVizrwCJ4f7W43+rVq2y3qdQKGAymdChQwc8/PDDcHNzs+EnIXuorVORlq+VdJZAIQpICFPxZAkROR3BcuOh+5soLy+Hr68vysrKHGJNfUOmplUJgmYNCcAL99wOAPDw8MBDDz2EyZMnY9SoUQwGXEiRTo9RK3bDIOHxQHeliOTZw5lzgogcQnOe3043Q7AyJbfF9etNvwYQ/0i9iM7Dp2He+P547rnn4O7uLvEoyRkE+3li0fhozNsoXXVC1qkgImflVMcON2RqWhwM/J7nkCnolvgggwEXNyVOjTljIiVpi3UqiMiZOU1AUKTTY8GWbEnbfH1LNopkzmlPjm9WUgSWTYyBu1JsdgVEhSjAXSnirYkxeC4pXKYREhHJz2kCgvmbsmCU+IiY0WzB/E3STReT85oSp0by7OFICFPVvGC59b6C2sAhIUyF5NnDOTNARE7PKQKC3EsVSM0rlfzMuMlsQWpeKfJKKiRtl5xTbZ2KN4d6oPzgVqjczfUyGgoAQlSemB4fguTZd2DtjHjuGSCiNsEpNhWuz9A0WlmwpRSigHXpGiwcHy152+R8dDodnnn0AVRUVOCrlx/CkMQ7WaeCiFyCU/xmSzldIkswANTMEqTklGAhGBC4stTUVJw6dQorV65ERUXNjNH58+etdSqIiNo6h18yqDQYoZF5459Gq0eVwShrH+TYFi1ahCeffBLHjh2zvvbTTz+hCWk6iIjaBIcPCAq1VZD7V7IFQIG2SuZeyFEZjUbk5+fXe/2zzz7DXXfdZYcRERHZnsMHBNUSZpFzhH7I8Xz22Wc4e/Zsg9eGDRtm49EQEdmHwwcEbkrbDNFW/ZDjmTRpEp599tkGrz355JM2Hg0RkX04/FMwVOVV7+iX1IRf+yHX5Ovri7///e91XgsJCUFkZCSUSqfYd0tE1GoOHxB4uSuhlvmct1rlyaNkLs7Ly8uaxvq+++5DXl4eTp8+DT8/PzuPjIjINhw+IACApKiAZqeUbSqFKCApMkCWtslxVRmMyC4uw2HNZWQXl6HKYIRCoUCHDh3w9ddfc2aAiFyOU/zWmxqvxpp9BbK0bTJbMG0w0866gtxLFVifoUHK6RJodPo6p1cEAB2nv4PEnn7QXKlGRCCLXhGRa3GKgCAi0BuJ4f5Iy9dKmqBIIQpICFMhPMBbsjbJ8RTp9Ji/KQupeaU3zXhpAdCuUxAyrwgY/c4eJIb7Y8mEGKYlJiKX4RRLBgCwZEIMlFIuG1gsMF2vxl3+V2AymaRrlxzKhkwNRq3YjbR8LQA0GlDWXk/L12LUit3YkKmRfYxERI5AsDQhFVt5eTl8fX1RVlYGHx8fW4yrQRsyNZi3UbrqhFd+WImyw9shiiJ69eqF2NhYREdHIzo6GsOGDeOGMie3MiUXy3fktLqdOWMiMSspQoIRERHZVnOe306xZFBrSpwapZUGSX7Jzx0ThY59pmHatO0wm83Izs7GyZMnIQgCTCYTxo0bh++//16CUZM9bMjUSPLvBACW78hB5w7uLHFMRG2a0ywZ1JqVFIFlE2PgrhSbffJAIQpwV4p4a2IMnksKx9SpU5GUlARBqGnHbDZblw9eeOEFycdOtlGk02PBlmxJ23x9SzaKZK6pQURkT04XEAA1MwXJs4cjIUwFAI0GBrXXE8JUSJ49vM43vWXLltUrYBMdHY2xY8dKPGqylfmbsmCUuDqm0WzB/E3SLVcRETkap9pD0BDrUbKcEmi09Y+SqVWeSIoMwLTB6pueJrjvvvuwfXvN0oFSqUR1dTVCQkKwZ88eqNWcJnYmuZcqMPqdPbK1nzz7Dp5KISKn0Zznt9MHBDeqMhhRoK1CtdEMN6WIUJVXkzIQHj16FLGxsfDw8MDRo0fx73//GytXroRSqcTq1avxhz/8wQajJyks3JKNtRmFkh5PraUQBUyPD8HC8dGSt01EJIfmPL+dcsngZrzclYgO8kV/dSdEB/k2OR1xv3798M4772Djxo2IiIjAu+++i5SUFLi7u2PGjBm4++67YTQaZR49SSHldIkswQBQcyQxJadElraJiOytTQUErfGnP/0J48aNs/75zjvvRElJCeLj4/H9998jMDAQx44ds+MIqTGVBiM0Mm/802j1qDIwOCSitocBwS14enoiPT0dS5cuxZUrVxAbG4u//e1v9h6WS9NqtaioqGjwWqG2CvLMDfzGAqBAWyVzL0REtseAoAnmzZuHY8eOQaVS4bXXXsPtt9+OysrKOvfo9TySZgtDhw6FSqXCvffeizVr1kCr1VqvVRvNNhmDrfohIrIlBgRNFB0djQsXLmD8+PE4ePAgAgMDkZycDADYunUrOnXqhO3bt9t5lG1fx44dcf36dWzfvh1PPPEEAgICEBsbiwkTJmDdZ2tsMgY3JX9siKjt4W+2ZlAqlfjmm2/w2Wef4fr16xg9ejSmT5+O6dOno7q6Gn/5y19gNjft22ND5Xfp5goLC/Hxxx/jypUrAGBNIGU2m3H06FFs3rwZK5cuABo/NNMqAoBQlZesfRAR2UObOnZoS8XFxRg2bBjOnj1b5/Wvv/4aDz74YIPvaaz8rtrPE0lRAZgar0ZEoOudda+ursbevXuRmpqKw4cP4/Tp07hw4QIqKipuGmgJggClUolXXnkFr7/+Okb8cw8KZdxYGKLyxO45SbK1T0QkJZfNQ2BrS5YswV//+lfrnwVBQHh4OE6ePAmFQmF9vSnld2vVXm/L5Xc1Gg1+/PFHZGRkICsrC4WFhSgtLYXBYKhzX/v27dG5c2f06NEDffv2xZAhQ2AymfDYY48BqPn/ffvtt+OLL75Az549ATAPARHRjRgQ2MDRo0cxYMCABr+5fvLJJ3j88ccB1BTZWbAlG0azpVkPKYUoQCkKWDQ+GlOcsKhOdXU10tLSsGfPHhw6dAg5OTkoLi6u921foVDAx8cH3bp1Q1RUFAYOHIg777wTcXFxUCrr55HIyclBVFQUBEHAa6+9htdee63OfcxUSET0mzZb7dCRKJVKDBgwACdOnKh3wmDGjBkYN24c/nuyosUV90y/BhDzNmahtNLgsOV3i4qK8OOPPyI9Pb1J3/b79euHmJgYDBkyBCNHjkSXLl2a1V94eDhee+01jBs3DgkJCfWuRwR6IzHcH2n5WklnCRSigIQwFYMBImqzOEPQShaLBUVFRcjOzkZ2djY+//xzHD16FIEJE+A27AnJ+nlrYozdyu829du+KIrw9fW1ftsfMGAAhg8fjvj4+Aa/7culSKfHqBW7YZDqeKDFAsFiwpqHemL47X2kaZOIyAa4ZGBnB08V4KE1x2AWFI3f3ETuShHJs4ffdE9BQUEBVCoVvL1b/g323Llz+PHHH7Fv3z4cP34cBQUFN/227+/vjx49eli/7Y8YMQJBQUEt7ltqGzI1mLdRuuqEuu/fRcXRH+Dj44Nhw4ZhwIABiI2NRWxsLHr06AFR5IEdInI8XDKws3d+vgRBoQQknLKuLb+7dkZ83deNRixduhQLFy7E7NmzsXz58lu2U11djfT0dOzatavOTv7y8vIGv+2Hh4db1/bvuOMODB482Kbf9ltqSpwapZWGFi/Z3GjumChcUNyON4/+gPLycnz33Xf44YcfrEcfX3jhBfzrX/9qdT9ERPbk+L/ZnUzupQqk5pVK3q7JbEFqXinySiqs69hnz57FI488gv3798NiseDIkSPW+2u/7deu7RcUFECr1eLatWt12q39th8TE4M+ffogISHB4b7tt9SspAj4d3Bv1abOxeOjMTlODWPiQqxduxYajQbAb3kQAGDMmDGSj52IyNYYEEhsfYam0aOFLaUQBaxL12DBfb2xbt06PPXUUzAYDKhd9dm9ezc6derU4Ld9Hx8f9OzZE5GRkRg4cCCGDx/uNN/2W2NKnBpDe/o3+9hnQpiqzrFPpVKJxYsXW0+P1Jo4cSLuueceOT8CEZFNcA+BxIa/nSJrYhxvXMOFD56qk8P/Rt26dbOu7Q8ePBgjR45Et27dZBuPM7EmhsopgUbbQGIolSeSIgMwbbC6wdME169fR3h4OIqKiiAIAiwWCywWC5588kmsXr3aZp+DiKipuKnQTioNRsQs/EHeinsWC8o//iOulF6CxWKBKIp1ZgMOHz6M2NhYOUfQJlQZjCjQVqHaaIabUkSoygte7o3Plnz00UeYOXMm/Pz8sHv3bjzwwAM4c+YMIiMjsW/fPvj5+dlg9ERETdOc5ze3RkvIFuV3IQhIPXIK165dww8//IAZM2bUeQjl5ubKPYI2wctdieggX/RXd0J0kG+TggEAmD59Oh577DFs3rwZffr0QV5eHp544gnk5OSgW7du2Llzp8wjJyKSBwMCCdmy/K6bmxvGjBmD//znPygpKcGePXuwcOFCDB061CZjcFVubm749NNPkZiYaH3t448/xn//+1+YTCaMGTMGf/7zn+u978ZNiEREjogBgYRsVRb39/0oFAokJiZiwYIFbeJ0gDOaNGkSzp49i+DgYPzzn/9Ev379UFFRAQB48cUX0bt373r5HIiIHAkDAgmFqrwgyNwHy+86rm7duqGgoAAPP/wwjh07hq5du2LBggX417/+hZycHHz66adNbovlsYnI1ripUGJynzJg+V3n8Omnn2LGjBnWpQJBEBAUFISzZ8+iXbt2Db6H5bGJSGrcVGhHSVEBUIjyzBMoRAFJkQGytE3SevDBBxESEmL9s8Viwfnz5/HZZ5/Vu7dIp8f0jzIw+p09WJtRiMLfBQMAYAFQqNNjbUYhRr+zB9M/ykCRjIEnEbkeBgQSmxqvliUpEVCTrXDaYOcrheyK5s6di/z8/Hqv//Wvf8X169etf96QqcGoFbuRll+TV6Kxfzu119PytRi1Yjc2ZGokHDURuTIGBBKrLb8r9SyBQhSQGO7P8rtOokuXLujatav1z4JQ8+/h0qVL+MMf/gAAWJmSi3kbs2AwmpsdRJrMFhiMZszbmIWVKTxqSkStxz0EMpC8/C4ar3ZIjkmn0+Ho0aM4cuQIdu3ahW3btsFkMmHm0k+ws6yzZP3Yszw2ETkuZip0AFKX3+Uv/LbBZDLh1WUr8FVlJEywXXlsInJN3FToAKbEqTFnTKQkbc0dE8VgoI1QKBQ41yUREKUtKlVbHpuIqKUYEMhoVlIElk2MgbtSbPaeAovZBDeFgLcmxuC5pHCZRki2VlseW+qNpzeWxyYiagkGBDKbEqdG8uzhSAhTAUCjgUHt9evnsnHp41kYFiTdtDLZX215bDnUlscmImoJBgQ2EOznibUz4rHzxTswPT4EISrPehkNBdQkHZoeH4Lk2Xcg8MRXKL9wFmFhYVizZg2asNWDnEDK6RJZj6Wm5JTI0jYRtX3SLmTSLUUEemPh+GgsRHSj5XfvvvtuHDlyBNXV1XjiiSfw5Zdf4sMPP0S3bt3s+AmoNSoNRmhkTiak0epRZTA2uXojEVEtzhDYSWPldzt27AhR/O2vZ+fOnbjtttvw5Zdf2nqoJBFblMe2ACjQVsncCxG1RQwIHJSPjw/M5t/yGJhMJlRWVuLtt9+246ioNWxZHpuIqLkYEDiohs6LzpkzBz/++KMdRkNSsFd5bCKipuBvDgd1Y0Dg7+8PABg7dix8fX3tNSRqJZbHJiJHxoDAQcXHx+PRRx/FTz/9hFOnTkGhUGD69OkwGAx4++238fjjj/PkgZPxcldCLXMmQbXKkxsKiahF+JvDQfn7+2P9+vXWPz/99NNYtWoVunTpgitXrgAA3n//fXh4eNhphNQSSVEBWJtRKMvRQ5bHJqLW4AyBEzhy5AiOHTsGANZgAKjJUU3OheWxichRMSBwcCUlJYiLi0Nqamq9awwInA/LYxORo2JA4OA6d+6MBQsWQKlUQqGom8aYAYFzWjIhBkqJAwKlKGDJhBhJ2yQi18KAwMEJgoBXX30VBw8eRO/evSEIvz1IGBA4p2A/TywaHy1pm4vHR7P0MRG1CgMCJ9G3b18cPHgQixYtsgYFaWlpde6pMhiRXVyGw5rLyC4uQ5XBaI+hUhOwPDYRORrB0oSza+Xl5fD19UVZWVmDCXPItnbv3o2RI0ciISEBH329DeszNEg5XQKNTl8nNa4AQO3niaSoAEyNVyMikOvLjmZDpgYLtmTDaLY0a7OhQhSgFAUsHh/NYICIbqo5z28GBE5q9br/YtH3OXBT94NCFG75MKm9nhjujyUTYji17GCKdHq8sG4fDl+4BoUAmG7xE8m/SyJqDgYEbVxrv1UuGh+NKfxW6VBiY2Nx4pwOHfrfBY+w29GuU1fghv0iAmqSDiVFBmDaYDVPExBRkzTn+c3ERE5mZUoulu/IadF7Tb8GEPM2ZqG00oBZSRESj45aKiEhAVmrV+Ny8n9wGf+B6OYBRccuUIeG4ZtN/6tXHpuISGrcVOhENmRqWhwM/N7yHTn4MlMjSVvUevfdd1+d6pbm6qu4XnIWqxbPbbA8NhGR1BgQOIkinR4LtmRL2ubrW7JRpNNL2ia1zLBhw+ocKQWAl19+GWPHjrXTiIjI1TAgcBLzN2XBKHHKW6PZgvmbsiRtk1pm6dKldYpVKZVKLF682I4jIiJXw4DACeReqkBqXqnkOfBNZgtS80qRV1IhabvUPDt27MCyZcvqvGY0Gq31K4iIbIEBgRNYn6GRPPd9LYUoYF069xLY08yZM+uVshYEAdu2bbPTiIjIFTEgcAIpp0tkrZCXklMiS9vUuCqDEbMX/QMPPjUHIbFDIbRrDwCwWCzYtWuXfQdHRC6FW5cdXKXBCI3MG/80Wj2qDMY6O9l/+eUXfPbZZ9i0aRPeffdd9O/fX9YxuJLcSxW/yy7pCXS6Exh3J9TjLOjq7YaeHlcxsW+AvYdKRC6EAYGDK9RWQZ65gd9YABRoq9CrizeSk5OxevVqbNmyBUZjTS2E/Px8BgQSKNLpMX9TFlLzSm+RXVLAhYrrKKlqh73JOmwqyGBGQiKyCQYEDq7aaG78JglMemgy8jN/wvXr1yEIQp017Y4dO9pkDG3ZjdklATS6BFR7PS1fi1ErdjO7JBHJjgGBg3NT2mabxy8XL+D69esAUG+D26hRoyAIAtzc3ODp6QkfHx+oVCoEBASgW7duUKvV6NmzJ2677Tb06tULnp78NnsjZpckImfAgMDBhaq8IACyLhsIADQnDmL3jzvw9NNP4/z583Wy5k2ePBmlpaX45ZdfoNPpcOXKFVy4UBNANFQKQxAEtGvXzho8+Pn5ISAgAEFBQQgJCUFYWBiioqLQu3dveHu37Zz8UmeX7NzBndUNiUgWLG7kBIa/nYJCGTcWhqg8sXtOEgBAr9fjb3/7G95++20YjUa4u7vj6tWr9bLo1SovL8fJkydx+vRp5Ofno7CwEMXFxSgpKYFOp0N5eTn0en2jwYOHhwe8vb3rBA9qtRphYWGIjIxEdHS00y1dFOn0GLViNwwSLvu4K0Ukzx7OPQVE1CSsdtjGLNySjbUZhbIcPVSIAqbHh2Dh+Og6r584cQJPPfUUrl+/jvT0dEn6qqqqsgYPZ86cgUajwfnz51FSUgKtVmsNHqqrqxsMHgDUCR46deqEzp07o2vXrnWCh969e6Nz586SjPlmrl69ii+++AIPP/wwOnTo0OA90z/KQFq+VtK/N4UoICFMhbUz4iVrk4jaLgYEbUzupQqMfmePbO0nz77D4crpXrt2DadPn8apU6eQl5eHwsJCnD9/HpcuXYJOp0NZWZk1eLhxeeNGSqUSHh4e6NChQ53gITg4GD169EBkZCR69eqFLl26QBSbt1fjq6++wuTJk9G1a1e8//77uP/+++tcd8W/MyJyPCx/3MZEBHojMdxftm+bjvhgad++Pfr164d+/fo1em91dTVyc3Nx6tQpnDlzBmfPnsW5c+dw6dIlaLValJWV4ezZszh16tQtgwd3d3d4e3ujY8eO8Pf3twYPoaGhiIiIQK9evRAcHAxRFHHhwgWIoohLly7hgQcewL333ouVK1ciJCQEwG/ZJeWa1VmXrqk3q0NE1BqcIXASXI+WhtFoxJkzZ6wzDwUFBTh37hwuXrwIrVaLK1euoKqqCgaDASaTqcE2FAoFRFG0nsoAavZCiKKI++67D4sXL8az3/+CostXZfscN+77ICK6GS4ZtFEbMjWYt1G66oRvTYzhjvVbMJvNKCgowMmTJ5Gbm2udebh48SKOHz+O8vLyBt8nuHlAPfsr4CYbMaUgADi+cGyd7JJERL/HJYM2akqcGqWVBkmOsc0dE8VgoBGiKCIsLAxhYWH1rt1zzz347rvvrPcBwJgxYzBixAh06XU7XvtZ3nTTtdklo4N8Ze2HiFwHAwInMyspAv4d3K1Z75qzRq0QBShFAYvHRzMYaKXLly8DAMLCwvDMM8/gscceQ0BATe2Bw5rLwM9pso/BVlksicg1MCBwQlPi1Bja078JefFr1F5PCFMxL75EVq1ahcrKSgwbNqxejgZbZZe0VT9E5BoYEDipYD9PvBirxBh/N2RX+2HdT4eh9O1SZ91aAKBWeSIpMgDTBqsd8jSBs7pVsSdbZZcMVXnJ2AMRuRoGBE5sxowZOHr0qPXPAUHBmPGneRg0JAERPXsgVOXFTWd24OWuhNrPU9bskmqVJ/9uiUhSnHN0YoMGDaqTUKekuAhLX34Of316KqKDfPnAsKOkqAAoRHlOGShEAUmRAbK0TUSuiwGBExswYECDiXb+/ve/22E0dKOp8WpZkhIBNRUQpw3mplAikhYDAidlMBjw/vvv13t96tSpuOeee+wwIrpRbXZJqWcJLGYT/AyXYPhFg2vXrknaNhG5NgYETurll1/GsWPH6r3epUsXO4yGGrJkQgyUEgcEosWMrI/no0+fPvD09ERQUBDuvPNOPPXUU3jvvfdgNBol7Y+IXAcDAifl5eXVYNap7du322E01JBgP08skrjewJIH+6OTW80ykcViwYULF7B792588MEHeOGFF6DVaiXtj4hcBwMCJ/Xmm2/iypUrePLJJwEA999/P4YPH46ePXvaeWR0oylxaswZEylJW3PHROGRQSHYsGFDg9dfeeUVBAYGStIXEbkebkN3QlUGIwq0Vag2mtEuoAe6h/bE5s2b7T0sugmps0uOGDECY8eORXJysrUAk8ViQadOnWQZPxG5BhY3chK5lyqwPkODlNMl0Oj09ZLehPh5IikqAFPj1YgIZAIiR1Sk0zc7u2RiuH+D2SWzs7MRExMDi8UCpVKJ9u3bo7KyEgMHDkRycjI6duwo86chImfAaodtiJQPEXIM1uAupwQabd3grjnZJf/4xz/iww8/xD//+U/MmjULEydOxNatW+Hu7o6PP/4Yjz76qOyfhYgcGwOCNmJDpqZV08yLxkdjCosYObQbl3/clGKzskteuXIFmzdvxmOPPWZNULVp0yZMnToVV69exciRI7F161a0b99ezo9ARA6MAUEbsDIlV5Iyx3PGRGJWUoQEIyJnUVlZiXHjxuHnn3+Gl5cX/ve//2Hs2LH2HhYR2UFznt88ZeCANmRqJAkGAGD5jhx8mamRpC1yDh06dMDevXvxwQcfoLq6GuPGjcPDDz/cYFZLIqJaDAgcTJFOjwVbsiVt8/Ut2SiSsdAOOaaZM2fi3Llz6NOnD77++mt07twZmZmZ9h4WETkoBgQOZv6mLBglzoFvNFswf1OWpG2ScwgICEBWVpY1b0V8fDxmzZrF2QIiqocBgQPJvVSB1LxSyYvimMwWpOaVIq+kQtJ2yXnMnz8feXl5UKvVWLVqFUJDQ5Gbm1vnnvPnzzP1MZELY0DgQNZnaGQtmbsunXsJXFmPHj1QUFCAP/3pTzh37hxuu+02LFq0CABw6tQphIeH47nnnrPzKInIXnjKwIEMfzsFhTKu9YeoPLF7TpJs7ZPzOHToEMaNG4dffvkFt912GxQKBbKzsyEIAo4fP47evXs3qZ3WHJskIvk15/nNn1wHUWkwQiPzxj+NVo8qg5G/sAkDBgzAxYsXMX36dHz++efW10VRxNy5c7Ft27abvvdWWTMFAGpmzSRySlwycBCF2qp66YilZgFQoK2SuRdyFqIoYvbs2RCE35apTCYTvvvuO6SkpNS7v0inx/SPMjD6nT1Ym1GIwgZSaFsAFOr0WJtRiNHv7MH0jzJ4woXISTAgcBDVRtvs+rZVP+Qcpk6dioZWDZ944ok6JxE2ZGowasVupOXXlFdubONr7fW0fC1GrdiNDcyFQeTwGBA4CDelbf4qbNUPOT6LxYIhQ4agZ8+eaNeuXZ1rhYWFuPfee2EymbAyJRfzNmbBYDQ3+wSMyWyBwWjGvI1ZWJmS2/gbiMhuuJjsIEJVXhAAWZcNhF/7IQIAQRCwZs0aADVLBefOncOZM2dw7Ngx/Pvf/8b27dvx4MsrcLhdL0n6W74jB507uFvLOBORY+HXRQfh5a6EWubqhGqVJzcUUoMUCgVCQkIwYsQIvPjii8jPz8fWXfuQ3V6aYKAWs2YSOS4+HRxIUlQA1mYUSp6YCAAsZhOK0rdjypTVEAQBFRUVqKioQHl5OSIiIvDVV19J3ic5ty9yAZNF2nmr2qyZa2fES9YmEUmDAYEDmRqvxpp9BbK0LYgKFO36HGe152Rpn9qW2qyZUrsxa2Z4AI8kEjkSLhk4kIhAbySG+0uerVAhChgWrsKwmPAGr8+dO1fS/sj5MWsmkethQOBglkyIgVLiX8RKUcDSCX2xdetWREdHQxTr/rU//fTTePnll1FdXS1pv+S8Uk6XyLJ0BdTMEqTklMjSNhG1HAMCBxPs54lF46MlbXPx+GgE+3nCy8sL27Ztg6+vL0RRhCAIuPPOOyEIAv7+97/Dy8sLDz74IC5evChp/+RcbJk1k4gcBwMCBzQlTo05YyIlaWvumKg6x7xCQkLwzTffQBAEuLu7Y+PGjSgrK8OaNWvQrVs3/O9//0PXrl0RHx+PzMxMScZAzoVZM4lcEwMCBzUrKQLLJsbAXSk2ey1XIQpwV4p4a2IMnkuqv28gMTERmzdvxpo1a9CpUycAwP/7f/8PBQUF2LdvH+Li4rB//34MGjQIoaGhWLdunSSfiZwDs2YSuSYGBA5sSpwaybOHIyFMBQCNBga11xPCVEiePfyWCWDuvfdeTJ48ud7rgwcPxv79+3H+/HlMmDAB58+fx/Tp09GxY0f89a9/hdHIad62jlkziVwTfyIdXLCfJ9bOiMfOF+/A9PgQhKg88fuwQEBNaePp8SFInn0H1s6IR3ArkxwFBQVh48aNqKqqwpw5c2A2m7FkyRJ4enpi8uTJKCnhprC2qjZrppyYNZPI8QiWhiqb/E5z6imT/OxVg/7DDz/EokWLcO7cOQiCgMGDB2PlypUYMGCA7H2TbQ1/OwWFMm4sDFF5YvecJNnaJ6IazXl+c4bACXm5KxEd5Iv+6k6IDvK1WTrimTNnoqioCKmpqejfvz/27duHgQMHomfPnvjyyy9l7bvKYER2cRkOay4ju7iMO9RllhQVIGsegqTIAFnaJqKW4wwBtZhGo8Hzzz+Pbdu2wWQyoWPHjnjhhRfw2muvQamsG6Rcv34dFy5cgFrd9MI2uZcqsD5Dg5TTJdDo9HV2vgsA1H6eSIoKwNR4NSICmfVOSrmXKjD6nT2ytZ88+w5mKiSyAc4QkE2o1Wp88803qKysxIsvvojr169j8eLF8PLywtSpU1Fa+lvq2z//+c8IDw9Henp6o+0W6fSY/lEGRr+zB2szClH4u2AAqDm2VqjTY21GIUa/swfTP8pg0RwJyZk1MzHcn8EAkQPiDAFJxmw244MPPsDixYtRXFwMQRAwdOhQLF26FKNHj8a1a9fg7++Pw4cPo3v37g22sSFTgwVbsmE0W5qVKU8hClCKAhaNj8YUlteVRJFOj1ErdsMg4fFAd6WI5NnDW73plYiahjMEZBeiKOKpp57C+fPn8dNPP6Fv377Yu3cvEhMTce3aNQDA5cuXce+99+Lq1av13r8yJRfzNmbBYDQ3O22uyWyBwWjGvI1ZWJmSK8nncXVyZs0kIsfDgIBkkZSUhCNHjiAnJwdubm7W100mE44dO4bHH38cN05ObcjUYPmOHEn6Xr4jB19msniOFOTMmklEjoUBAclq//799YomWSwWfPXVV9aZgyKdHgu2ZEva7+tbsrmnQCJyZs0kIsfBgIBktXPnzpte+/nnnxEaGoqXNhyAUeLKekazBfM3ZUnapitrbtZM4ddtoB0Nl/CfB9ScGSByAtxUSLLS6/U4e/YsvLy84OXlhQ4dOqB9+/YQBAF5eXn4ZON2rL/cQ7b+ebxNetbjoDkl0Gh/fwLEguu6C7iafwAVh7+DUXsO69atw9SpU+00WiLX1pznNwMCsquFW7KxNqOw2ZsIm0IhCpgeH4KFEm+Mo9/UZs0sLDqPByc8AIP2HMzVdTeMHjp0CP3797fTCIlcG08ZkNNIOV0iSzAA1Jw8SMlhzQU51WbNHD0gAokxPWC5fq3ePUFBQXYYGRE1FwMCsptKgxEamTf+abT6BtMc5+XloaKiQta+XUm7du2wefNmxMbG1rs2adIk6PXc4Enk6BgQkN0UaqvqZSCUmgVAgbYKAFBQUIBly5YhOjoaERERePPNN2Xu3bV4eHjg2Wefrff6zz//jEceecQOIyKi5rBNVRyiBlRLmAHvVt54cyly03fi0KFDEEURZrMZgiDA19fXJv27kvz8fOv/41pubm4IDAy046iIqCkYEJDduCltM0G18b9f4XrJWQCwPqgsFgu2bdsGQRBw++23Y/DgwejQoYNNxtOWFRUVwWw2w8fHB+Xl5ejbty/S0tIApTuyi8tsXrKbiJqOpwzIbqoMRvRZ+IPsywYBe5YhM21vo/cpFAp4eXnB398f3bt3R0REBGJiYhAXF4fbb7+9TsZFalhBQQGKioowZMgQ/HHO60j/RYmA2CRWqySyEx47JKcx/O0UFMq4sTBE5Yndc5Kwbds2PPHEE9DpdDCZTACAs2fPoqCgAJmZmTh+/Djy8vJw/vx5aLVa6PX6OtPeAKBUKuHt7Y3OnTtDrVYjMjIS/fr1Q3x8PGJiYiCK3JID1BRFmr8pC6l5pRAF4FaHSBSiAJPZgsRwfyyZEMM6B0QSY0BATsOWeQguX76M559/HuvXr0f79u2h1+shCDfPuKfT6ZCeno4DBw7gxIkTyM/PR3FxMS5fvoyrV6/i9z86bm5u8PX1RUBAAEJCQnDbbbehf//+GDx4MMLCwlwiYGC1SiLHwoCAnEbupQqMfmePbO03lKlw69atuHjxImbOnNmqts+dO4f09HQcOnQIJ0+eREFBAS5evIgrV65YqzveqH379ujYsSO6du2K0NBQ9OrVCwMGDMDQoUPRpUuXVo3FEaxMyZWkQNWcMZGYlRQhwYiIiAEBOZXpH2UgLV8r6SyBQhSQEKbC2hnxkrXZHGazGXl5eUhPT8eRI0dw6tQpFBYWoqSkBOXl5fUKPgmCAA8PD/j5+SEoKAhhYWGIjo7GwIEDMWTIEHTs2NEun6OpNmRqMG+jdLUj3poYw/oHRBJgQEBOpUinx6gVu2GQ8Biiu1JE8uzhDrsmbTQacezYMWRmZuLo0aPIycmBRqNBaWkpKioqYDTWTaYkiiK8vLygUqnQvXt3hIeHo0+fPoiLi8OgQYPQvn17O30S1/z7I3IWDAjI6fAbZl3Xrl3DgQMHcODAARw7dgx5eXk4d+4ctFotKisr6214VCgU1g2PwcHBiIiIQN++fTFo0CDExsZCqWzZEb/t27dj8+bNWLx4MQICAhq8py3O8BC1FQwIyClJtQY9d0wUnksKl2BEjqu8vBz79u3DoUOHcPz4cZw5cwbFxcXQ6XTQ6/X1Njy2a9cOPj4+1g2PUVFRiI2NRXx8PKKiom664XH69OlYt24dOnbsiP/85z946KGH6ly3xx4QImo6BgTktFq7S33x+GinnhmQysWLF60bHk+cOIGzZ8/iwoULuHLlCq5evVrvfnd3d3Ts2BGBgYHo0aOH9YTEW2+9hcOHD0MQBFgsFjz44IN4//334e/vD4DVKokcHQMCcmo3nmOvPad+MzzH3jJnz57Fvn37cOTIEZw8eRKFhYW4ePEiysvLYTAYbvnedu3a4fHHH8fs2bPx1NaLshaoqs0jQUQtw4CA2oTcSxVYn6FBSk4JNNoGMt2pPJEUGYBpg9WcVpaQ2WzGiRMnsHfvXjzzzDM3vU9w84D6pa9Q87chDwHA8YVjmeaYqIWa8/zmTxk5rIhAbywcH42FiEaVwYgCbRVz4duAKIro06dPnVTNoijCYrFg6NChmDJlCgYPHozTJVWYv0feEtK11Sqjg1iIikhu/I1KTsHLXcmHgo3VHn3s27cvHnvsMUyePBndu3e3Xhc1l4E9abKPw1ZVMYlcHQMCImpQ7969UVVVBU/Phvdl2Kpapa36IXJ1/Ekjopu6WTAAAKEqLxl3D9QQfu2HiOTHGQIiahEvdyXUfp6yVqsM9vNAO8GMs2fPoqioCOfOnUNRURF0Oh1efPFFdO3aVba+iVwNAwIiarGkqADZ8hBYzCYc3/El3P8yss7rtTkRxo4dy4CASEJcMiCiFpsar5YlGAAAQVTAkls/C6LFYoFKpcIdd9whS79ErooBARG1WESgNxLD/aEQpd1NoBAFJIb7Q5O1H/3796+XWrmyshJPPvkkzp07J2m/RK6MAQERtcqSCTFQShwQKEUBSybEwNvbG8nJyYiMjIRCobBed3NzwyeffILg4GCEhobizTffrFdSmoiahwEBEbVKsJ8nFklcb2Dx+GhrGmo/Pz/89NNP1hwI0dHRKC8vR3p6OsaOHYsLFy7g1VdfhYeHB+Li4rBx40ZJx0LkKhgQEFGrTYlTY86YSEnamjsmql6Bqq5du2LXrl2IiIjAnDlzAADx8fHYvn07rl69ik8//RR9+vTBwYMHMWnSJHh6euKBBx7A8ePHJRkTkStgLQMikoy9q1VWVlZi6dKlWLNmDYqLiwEAAQEBePTRR/H666+jU6dOLW6byBmxuBER2Y2jVKs8c+YMXn31VWzduhWVlZUAgNtuuw3PP/88nn766XobFYnaIgYERGR3jlSt8ocffsDf/vY37Nu3DyaTCUqlEkOHDsXrr7+OESNGyNo3kT0xICAih+Io1SqNRiNWrVqFVatWITc3FwDg7e2N+++/H3/7298QEhJi8zERyYkBARFRI0pLS7Fo0SJs2LABpaWlAIDu3bvjD3/4A15++eVb1nEgchbNeX5zEY2IXJK/vz/effdd/PLLLzh8+DDuvfdelJaWYvHixejQoQMGDBiAL774AmYzyy+Ta2BAQEQuLzY2Ft9++y30ej02bNiA/v374+jRo3j00Ufh6emJe+65B4cOHbL3MIlkxYCAiOhXgiBg8uTJOHjwIKqqqrBw4UIEBATgu+++w8CBA+Hv74/nnnsOv/zyi72HSiQ5BgRERA1o3749FixYAI1Gg4KCAjz22GO4fv063nvvPQQEBCAiIgIrVqyA0Wi06biqDEZkF5fhsOYysovLUGWwbf/UdnFTIRFRM+zatQuLFy9GamoqjEYjFAoF4uPj8eqrr+Kuu+6SpU/rEc7TJdDoGjjC6eeJpKgATI1XIyJQ3iOc5Fx4yoCISGZmsxn/+c9/8O9//xsnT54EAHh5eeHee+/FG2+8gYiIiAbfV1VVBVEU4eHh0WgfjpLkiZwXTxkQEclMFEU8/fTTOHHiBC5fvozZs2fDy8sLX375JSIjIxEUFIRXXnnFmiWx1qRJkxAVFYXz58/fsv0NmRqMWrEbaflaAGg0FXTt9bR8LUat2I0NmZpWfDpyRZwhICKSUHZ2Nl577TVr4SVBENCnTx+89NJLSEpKQo8ePWCxWBAREYG0tDT4+/vXa2NlSi6W78hp9VjmjInErKSGZyrINXDJgIjIAWzatAnLli3DgQMHYDaboVAoYDKZAAAKhQJ9+vTB7t274evra33PhkwN5m3MkmwMb02MaVXBKHJuXDIgInIAEyZMQEZGBq5evYolS5ZAEATrNZPJhGPHjmHUqFHQ6/UAavYMLNiSLekYXt+SjSKdXtI2qW1iQEBEJDM3NzeMHj263hFFi8WCAwcOoGvXrti5cyde2ZQFYzPKRjeF0WzB/E3SzThQ28WAgIjIBrZu3VrvtQ4dOsDLywvV1dW455EZ2JtX2ujmweYymS1IzStFXkmFpO1S28OAgIjIBmbOnIm1a9fip59+Qm5uLq5evYqKigpUVlZCr9fj2RVfQCEKjTfUAgpRwLp0njqgW7N9/VEiIhfUvXt3TJs2rcFrgiDg8MVqyWcHapnMFqTklGAhomVpn9oGzhAQEdlZpcEIjcwb/zRafYNpjqurq1FSUiJr3+QcGBAQEdlZobYK8swN/MYCoEBbBaDmhMOPP/6ImTNnonPnzujRowfLPBOXDIiI7K3aaJuH8brPN+Bidjq+/fZbaLVaKJVKGI1GdOrUCaLI74dNUWUwokBbhWqjGW5KEaEqL3i5t41Hadv4FERETsxNaZuH8T/efgvXS85a/1x7DFIURfzrX//C4MGDMXDgQCiVfDTcyFWKSzFTIRGRnVUZjOiz8AdZlw0EACMvf4fPPv4A169fv+W9bm5u8PX1RZcuXRAWFobevXvj9ttvx7BhwxAQECDjKB1LWyguxdTFREROZvjbKSiUcWNhiMoTu+ckoaioCI8//jh++uknAIBSqcSLL76IESNGYP/+/Th+/DjOnDmDCxcu4PLlyzAYDHXaEUURXl5e8Pf3R3BwMKKiohAbG4shQ4agX79+bWbpYUOmBgu2ZMNotjTr9IdCFKAUBSwaH40pDpAyujnPb84LERE5gKSoAKzNKJTl6KFCFJAUWfPNPjg4GMnJyVi9ejVmz56Na9euoXfv3rjrrrtw11131Xuv2WzG8ePHkZaWhiNHjuD06dPQaDT45ZdfUFhYiD179tS5393dHR07dkTXrl0RFhaGPn36IC4uDkOHDkWnTp0k/2xyaE1xKdOvAcS8jVkorTQ4VXEpzhAQETmA3EsVGP3OnsZvbKHk2XcgPKDu+vaZM2fwj3/8A6+//jq6dOnSonZLS0vx888/IzMzE9nZ2cjPz8eFCxdQVlaG6urqOveKoogOHTqgc+fOCAkJQVRUFPr374+EhAT06tXLIWYX2lpxKS4ZEBE5oekfZSAtXyvpLIFCFJAQpsLaGfGStdlURqMRhw8fRnp6Oo4cOYKcnBwUFRWhtLQUer0ev3/8tG/fHp06dUJQUBDCw8PRp08fDBo0CAkJCejQoUOrxlJdXY3k5GSMHTsWCoWiwXuKdHqMWrEbBglPfbgrRSTPHm63PQUMCIiInFBbfCDdyvnz5/Hzzz/j4MGDOHHiBM6ePYuLFy+ivLy83sZHhUIBb29vBAQEICQkBL169cKAAQOQkJCAnj17Njq7sG7dOkyfPh1xcXFYv349IiLqT+W3tYAMYEBAROS02tqUdUtVV1cjMzMT6enpOHbsGHJzc3Hu3DlotVpcvXq13uyCh4cH/Pz80K1bN4SHh6Nfv34YNGgQ4uPj4eHhgQULFuDNN98EULORcvny5Xj22WetgYQ9lmxsgQEBEZETa82mthvNHROF55LCJRiR4yksLMTevXtx6NAhnDhxAgUFBSgpKUF5eXm9MtNKpRKiKNbb0xAfH48vv/wSISEhWLglW9ZNndPjQ7BwvO1rSTAgICJycq099rZ4fLRTzgxIQa/XIyMjAxkZGcjKykJeXh4OHz580/wL/fr1gzh+MXTXG95bIIXaY5+2xoCAiKgNaAuJcRyFSqWCTqcDUHPawWw2w9vbG8HBwRgQn4DUwPtRk75JHgKA4wvH2jzNMfMQEBG1AcF+nlg7I/631Lk5JdBo9fUyGnb1bY8RUQF4YmioXdapHV11dbU1GAgKCsLUqVMxZcoU9O/fH4IgILu4DKnv7pV1DLXFpaKDfGXtpzUYEBARObiIQG8sHB+NqZfUWJNWgJ9Ol6D4ylUIQs032gtl1/D5fg325pW2iZz6UnNzc8Pnn3+O0NBQxMfH1zuRYKviUrbqp6UYEBARObiGlg5qg4FaFgCFOj3WZhRizb4CLh38ziOPPHLTa7YqLmWrflrKsUdHROTiNmRqMGrFbqTlawGg0Q2GtdfT8rUYtWI3NmRqZB+jswtVecm4e6CG8Gs/jowBARGRg1qZkot5G7NgMJqbfRzOZLbAYDRj3sYsrEzJlWmEbYOXuxJqmWdS1CpPm28obC4GBEREDmhDpkaSXAQAsHxHDr7kTMEtJUUFQCHKM09wY3EpR8aAgIjIwRTp9FiwJVvSNl/fko0iGcsrO7up8WpZkhIBNbM10wY7fk4IBgRERA5m/qYsGCV+OBnNFszfJF1K5LYmItAbieH+ks8SKEQBieH+TnEclAEBEZEDyb1UgdS8Usm/rZrMFqTmlSKvpELSdtuSJRNioJQ4IFCKApZMiJG0TbkwICAiciDrMzSyrmWvS+degpsJ9vPEIonrDSweH+00Rz8ZEBAROZCU0yWyrmWn5JTI0nZbMSVOjTljIiVpa+6YKKeqJ8GAgIjIQVQajNDIvPFPo9WjymBs/EYXNispAssmxsBdKTZ7tkYhCnBXinhrYozTVZpkQEBE5CAKtVX16hRIrTanPt3alDg1kmcPR0KYCgAaDQxqryeEqZA8e7hTzQzUcuwsCURELoQ59R1LU4pLCahJOpQUGYBpg9VOcZrgZhgQEBE5CObUd0y1xaUWIhpVBiMKtFWoNprhphQRqvJy+AyETdU2PgURURtQm1NfzmUDZ8ip78i83JUOXcK4NRgmEhE5CObUJ3tiQEBE5ECYU5/shQEBEZEDYU59shcGBEREDoQ59cleGBAQETkYV8+pT/bBgICIyMG4ek59sg8GBEREDsiVc+qTffDsCRGRg5qVFAH/Du5YsCUbRrOlWZsNFaIApShg8fhoBgPUJJwhICJyYK6YU5/sgzMEREQOztVy6pN9CBaLpdE5qPLycvj6+qKsrAw+Pj62GBcREd1CW86pT9JpzvOb/3qIiJxQW86pT/bBPQRERETEgICIiIgYEBAREREYEBAREREYEBAREREYEBAREREYEBAREREYEBAREREYEBAREREYEBAREREYEBAREREYEBAREREYEBAREREYEBAREREYEBAREREYEBAREREAZVNuslgsAIDy8nJZB0NERETSqX1u1z7Hb6VJAUFFRQUAIDg4uBXDIiIiInuoqKiAr6/vLe8RLE0IG8xmM4qLi+Ht7Q1BECQbIBEREcnHYrGgoqICQUFBEMVb7xJoUkBAREREbRs3FRIREREDAiIiImJAQERERGBAQERERGBAQERERGBAQERERGBAQERERAD+P4J0m6LGjQoUAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "net = to_networkx(dataset[0])\n",
    "print(dataset[0])\n",
    "nx.draw_networkx(net, with_labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3cfcb45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.lin = Linear(hidden_channels, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # 1. Obtain node embeddings \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index)\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "\n",
    "        # 3. Apply a final classifier\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2296c009",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN(hidden_channels=64)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
    "        out = model(data.x, data.edge_index, data.batch)  # Perform a single forward pass.\n",
    "        loss = criterion(out, data.y)  # Compute the loss.\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "        out = model(data.x, data.edge_index, data.batch)  \n",
    "        pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "        correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
    "    return correct / len(loader.dataset)  # Derive ratio of correct predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "389d1833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Acc: 0.6600, Test Acc: 0.6556\n",
      "Epoch: 002, Train Acc: 0.6600, Test Acc: 0.6556\n",
      "Epoch: 003, Train Acc: 0.6600, Test Acc: 0.6556\n",
      "Epoch: 004, Train Acc: 0.6600, Test Acc: 0.6556\n",
      "Epoch: 005, Train Acc: 0.6600, Test Acc: 0.6556\n",
      "Epoch: 006, Train Acc: 0.6600, Test Acc: 0.6556\n",
      "Epoch: 007, Train Acc: 0.6600, Test Acc: 0.6556\n",
      "Epoch: 008, Train Acc: 0.6600, Test Acc: 0.6556\n",
      "Epoch: 009, Train Acc: 0.7333, Test Acc: 0.7285\n",
      "Epoch: 010, Train Acc: 0.7467, Test Acc: 0.7550\n",
      "Epoch: 011, Train Acc: 0.7267, Test Acc: 0.7417\n",
      "Epoch: 012, Train Acc: 0.7267, Test Acc: 0.7417\n",
      "Epoch: 013, Train Acc: 0.7400, Test Acc: 0.7417\n",
      "Epoch: 014, Train Acc: 0.7267, Test Acc: 0.7483\n",
      "Epoch: 015, Train Acc: 0.7267, Test Acc: 0.7417\n",
      "Epoch: 016, Train Acc: 0.7133, Test Acc: 0.7417\n",
      "Epoch: 017, Train Acc: 0.7333, Test Acc: 0.7616\n",
      "Epoch: 018, Train Acc: 0.7000, Test Acc: 0.7020\n",
      "Epoch: 019, Train Acc: 0.7533, Test Acc: 0.7550\n",
      "Epoch: 020, Train Acc: 0.7133, Test Acc: 0.6887\n",
      "Epoch: 021, Train Acc: 0.7467, Test Acc: 0.7417\n",
      "Epoch: 022, Train Acc: 0.7467, Test Acc: 0.7616\n",
      "Epoch: 023, Train Acc: 0.7400, Test Acc: 0.7616\n",
      "Epoch: 024, Train Acc: 0.7400, Test Acc: 0.7483\n",
      "Epoch: 025, Train Acc: 0.7467, Test Acc: 0.7550\n",
      "Epoch: 026, Train Acc: 0.7333, Test Acc: 0.7351\n",
      "Epoch: 027, Train Acc: 0.7333, Test Acc: 0.7351\n",
      "Epoch: 028, Train Acc: 0.7400, Test Acc: 0.7616\n",
      "Epoch: 029, Train Acc: 0.7400, Test Acc: 0.7616\n",
      "Epoch: 030, Train Acc: 0.7333, Test Acc: 0.7417\n",
      "Epoch: 031, Train Acc: 0.7400, Test Acc: 0.7417\n",
      "Epoch: 032, Train Acc: 0.7467, Test Acc: 0.7616\n",
      "Epoch: 033, Train Acc: 0.7467, Test Acc: 0.7616\n",
      "Epoch: 034, Train Acc: 0.7600, Test Acc: 0.7748\n",
      "Epoch: 035, Train Acc: 0.7533, Test Acc: 0.7682\n",
      "Epoch: 036, Train Acc: 0.7600, Test Acc: 0.7616\n",
      "Epoch: 037, Train Acc: 0.7467, Test Acc: 0.7616\n",
      "Epoch: 038, Train Acc: 0.7733, Test Acc: 0.7815\n",
      "Epoch: 039, Train Acc: 0.7667, Test Acc: 0.7815\n",
      "Epoch: 040, Train Acc: 0.7600, Test Acc: 0.7682\n",
      "Epoch: 041, Train Acc: 0.7600, Test Acc: 0.7748\n",
      "Epoch: 042, Train Acc: 0.7667, Test Acc: 0.7682\n",
      "Epoch: 043, Train Acc: 0.7667, Test Acc: 0.7748\n",
      "Epoch: 044, Train Acc: 0.7667, Test Acc: 0.7748\n",
      "Epoch: 045, Train Acc: 0.7667, Test Acc: 0.7748\n",
      "Epoch: 046, Train Acc: 0.7800, Test Acc: 0.7815\n",
      "Epoch: 047, Train Acc: 0.7600, Test Acc: 0.7616\n",
      "Epoch: 048, Train Acc: 0.7533, Test Acc: 0.7616\n",
      "Epoch: 049, Train Acc: 0.7800, Test Acc: 0.7881\n",
      "Epoch: 050, Train Acc: 0.7867, Test Acc: 0.7881\n",
      "Epoch: 051, Train Acc: 0.7533, Test Acc: 0.7616\n",
      "Epoch: 052, Train Acc: 0.7467, Test Acc: 0.7616\n",
      "Epoch: 053, Train Acc: 0.7667, Test Acc: 0.7748\n",
      "Epoch: 054, Train Acc: 0.7867, Test Acc: 0.7881\n",
      "Epoch: 055, Train Acc: 0.7667, Test Acc: 0.7682\n",
      "Epoch: 056, Train Acc: 0.7667, Test Acc: 0.7682\n",
      "Epoch: 057, Train Acc: 0.7600, Test Acc: 0.7616\n",
      "Epoch: 058, Train Acc: 0.7333, Test Acc: 0.7417\n",
      "Epoch: 059, Train Acc: 0.7600, Test Acc: 0.7616\n",
      "Epoch: 060, Train Acc: 0.7867, Test Acc: 0.7947\n",
      "Epoch: 061, Train Acc: 0.7667, Test Acc: 0.7748\n",
      "Epoch: 062, Train Acc: 0.7667, Test Acc: 0.7748\n",
      "Epoch: 063, Train Acc: 0.7933, Test Acc: 0.7881\n",
      "Epoch: 064, Train Acc: 0.7933, Test Acc: 0.7947\n",
      "Epoch: 065, Train Acc: 0.7600, Test Acc: 0.7616\n",
      "Epoch: 066, Train Acc: 0.7733, Test Acc: 0.7682\n",
      "Epoch: 067, Train Acc: 0.7867, Test Acc: 0.7881\n",
      "Epoch: 068, Train Acc: 0.7667, Test Acc: 0.7682\n",
      "Epoch: 069, Train Acc: 0.7600, Test Acc: 0.7616\n",
      "Epoch: 070, Train Acc: 0.7867, Test Acc: 0.7881\n",
      "Epoch: 071, Train Acc: 0.7933, Test Acc: 0.7881\n",
      "Epoch: 072, Train Acc: 0.7600, Test Acc: 0.7616\n",
      "Epoch: 073, Train Acc: 0.7800, Test Acc: 0.7748\n",
      "Epoch: 074, Train Acc: 0.8000, Test Acc: 0.8013\n",
      "Epoch: 075, Train Acc: 0.7800, Test Acc: 0.7748\n",
      "Epoch: 076, Train Acc: 0.7800, Test Acc: 0.7815\n",
      "Epoch: 077, Train Acc: 0.7800, Test Acc: 0.7748\n",
      "Epoch: 078, Train Acc: 0.7933, Test Acc: 0.7881\n",
      "Epoch: 079, Train Acc: 0.7933, Test Acc: 0.7881\n",
      "Epoch: 080, Train Acc: 0.7867, Test Acc: 0.7815\n",
      "Epoch: 081, Train Acc: 0.8067, Test Acc: 0.8079\n",
      "Epoch: 082, Train Acc: 0.7933, Test Acc: 0.7947\n",
      "Epoch: 083, Train Acc: 0.7800, Test Acc: 0.7682\n",
      "Epoch: 084, Train Acc: 0.7733, Test Acc: 0.7682\n",
      "Epoch: 085, Train Acc: 0.8000, Test Acc: 0.7947\n",
      "Epoch: 086, Train Acc: 0.7933, Test Acc: 0.8013\n",
      "Epoch: 087, Train Acc: 0.7867, Test Acc: 0.7947\n",
      "Epoch: 088, Train Acc: 0.7733, Test Acc: 0.7815\n",
      "Epoch: 089, Train Acc: 0.7800, Test Acc: 0.7748\n",
      "Epoch: 090, Train Acc: 0.7667, Test Acc: 0.7682\n",
      "Epoch: 091, Train Acc: 0.7667, Test Acc: 0.7616\n",
      "Epoch: 092, Train Acc: 0.8000, Test Acc: 0.7947\n",
      "Epoch: 093, Train Acc: 0.7733, Test Acc: 0.7748\n",
      "Epoch: 094, Train Acc: 0.7800, Test Acc: 0.7815\n",
      "Epoch: 095, Train Acc: 0.7800, Test Acc: 0.7881\n",
      "Epoch: 096, Train Acc: 0.8000, Test Acc: 0.8013\n",
      "Epoch: 097, Train Acc: 0.7867, Test Acc: 0.7815\n",
      "Epoch: 098, Train Acc: 0.7733, Test Acc: 0.7682\n",
      "Epoch: 099, Train Acc: 0.8133, Test Acc: 0.8079\n",
      "Epoch: 100, Train Acc: 0.8133, Test Acc: 0.8079\n",
      "Epoch: 101, Train Acc: 0.7933, Test Acc: 0.7947\n",
      "Epoch: 102, Train Acc: 0.7800, Test Acc: 0.7815\n",
      "Epoch: 103, Train Acc: 0.7933, Test Acc: 0.8013\n",
      "Epoch: 104, Train Acc: 0.7933, Test Acc: 0.7881\n",
      "Epoch: 105, Train Acc: 0.8000, Test Acc: 0.7947\n",
      "Epoch: 106, Train Acc: 0.8067, Test Acc: 0.8079\n",
      "Epoch: 107, Train Acc: 0.7933, Test Acc: 0.7881\n",
      "Epoch: 108, Train Acc: 0.7800, Test Acc: 0.7815\n",
      "Epoch: 109, Train Acc: 0.7933, Test Acc: 0.7815\n",
      "Epoch: 110, Train Acc: 0.8000, Test Acc: 0.7881\n",
      "Epoch: 111, Train Acc: 0.7800, Test Acc: 0.7748\n",
      "Epoch: 112, Train Acc: 0.8067, Test Acc: 0.8013\n",
      "Epoch: 113, Train Acc: 0.8067, Test Acc: 0.8013\n",
      "Epoch: 114, Train Acc: 0.7867, Test Acc: 0.7947\n",
      "Epoch: 115, Train Acc: 0.8200, Test Acc: 0.8146\n",
      "Epoch: 116, Train Acc: 0.8133, Test Acc: 0.8079\n",
      "Epoch: 117, Train Acc: 0.8067, Test Acc: 0.8079\n",
      "Epoch: 118, Train Acc: 0.7867, Test Acc: 0.7881\n",
      "Epoch: 119, Train Acc: 0.7867, Test Acc: 0.7881\n",
      "Epoch: 120, Train Acc: 0.8000, Test Acc: 0.7881\n",
      "Epoch: 121, Train Acc: 0.7933, Test Acc: 0.7947\n",
      "Epoch: 122, Train Acc: 0.7800, Test Acc: 0.7881\n",
      "Epoch: 123, Train Acc: 0.8000, Test Acc: 0.8013\n",
      "Epoch: 124, Train Acc: 0.7933, Test Acc: 0.7947\n",
      "Epoch: 125, Train Acc: 0.8067, Test Acc: 0.8079\n",
      "Epoch: 126, Train Acc: 0.8067, Test Acc: 0.8079\n",
      "Epoch: 127, Train Acc: 0.8133, Test Acc: 0.8146\n",
      "Epoch: 128, Train Acc: 0.8067, Test Acc: 0.8079\n",
      "Epoch: 129, Train Acc: 0.7867, Test Acc: 0.7881\n",
      "Epoch: 130, Train Acc: 0.7933, Test Acc: 0.7947\n",
      "Epoch: 131, Train Acc: 0.8067, Test Acc: 0.8079\n",
      "Epoch: 132, Train Acc: 0.7733, Test Acc: 0.7881\n",
      "Epoch: 133, Train Acc: 0.8133, Test Acc: 0.8146\n",
      "Epoch: 134, Train Acc: 0.8000, Test Acc: 0.8013\n",
      "Epoch: 135, Train Acc: 0.8067, Test Acc: 0.8013\n",
      "Epoch: 136, Train Acc: 0.7933, Test Acc: 0.8013\n",
      "Epoch: 137, Train Acc: 0.8000, Test Acc: 0.8079\n",
      "Epoch: 138, Train Acc: 0.8000, Test Acc: 0.8146\n",
      "Epoch: 139, Train Acc: 0.8000, Test Acc: 0.8079\n",
      "Epoch: 140, Train Acc: 0.8000, Test Acc: 0.8079\n",
      "Epoch: 141, Train Acc: 0.8133, Test Acc: 0.8146\n",
      "Epoch: 142, Train Acc: 0.7733, Test Acc: 0.7815\n",
      "Epoch: 143, Train Acc: 0.8200, Test Acc: 0.8212\n",
      "Epoch: 144, Train Acc: 0.8200, Test Acc: 0.8278\n",
      "Epoch: 145, Train Acc: 0.8133, Test Acc: 0.8146\n",
      "Epoch: 146, Train Acc: 0.8067, Test Acc: 0.8146\n",
      "Epoch: 147, Train Acc: 0.8133, Test Acc: 0.8212\n",
      "Epoch: 148, Train Acc: 0.8000, Test Acc: 0.8079\n",
      "Epoch: 149, Train Acc: 0.8267, Test Acc: 0.8146\n",
      "Epoch: 150, Train Acc: 0.8133, Test Acc: 0.8013\n",
      "Epoch: 151, Train Acc: 0.7733, Test Acc: 0.7881\n",
      "Epoch: 152, Train Acc: 0.8133, Test Acc: 0.8013\n",
      "Epoch: 153, Train Acc: 0.8333, Test Acc: 0.8278\n",
      "Epoch: 154, Train Acc: 0.8000, Test Acc: 0.8146\n",
      "Epoch: 155, Train Acc: 0.8333, Test Acc: 0.8146\n",
      "Epoch: 156, Train Acc: 0.8333, Test Acc: 0.8411\n",
      "Epoch: 157, Train Acc: 0.8067, Test Acc: 0.8079\n",
      "Epoch: 158, Train Acc: 0.8200, Test Acc: 0.8212\n",
      "Epoch: 159, Train Acc: 0.8000, Test Acc: 0.8013\n",
      "Epoch: 160, Train Acc: 0.8133, Test Acc: 0.8079\n",
      "Epoch: 161, Train Acc: 0.8133, Test Acc: 0.8146\n",
      "Epoch: 162, Train Acc: 0.8333, Test Acc: 0.8344\n",
      "Epoch: 163, Train Acc: 0.8267, Test Acc: 0.8278\n",
      "Epoch: 164, Train Acc: 0.7933, Test Acc: 0.7947\n",
      "Epoch: 165, Train Acc: 0.8067, Test Acc: 0.8013\n",
      "Epoch: 166, Train Acc: 0.8200, Test Acc: 0.8278\n",
      "Epoch: 167, Train Acc: 0.8133, Test Acc: 0.8146\n",
      "Epoch: 168, Train Acc: 0.8200, Test Acc: 0.7947\n",
      "Epoch: 169, Train Acc: 0.8333, Test Acc: 0.8344\n",
      "Epoch: 170, Train Acc: 0.8000, Test Acc: 0.8013\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 171):\n",
    "    train()\n",
    "    train_acc = test(train_loader)\n",
    "    test_acc = test(test_loader)\n",
    "    print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "080dce6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.8944, -1.0701]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = dataset[13]\n",
    "\n",
    "print(model(graph.x, graph.edge_index, batch = torch.zeros(len(graph.x), dtype=int)))\n",
    "graph.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "aef88bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnnexplainer = Explainer(\n",
    "    model=model,\n",
    "    algorithm=GNNExplainer(epochs=300),\n",
    "    explanation_type='model',\n",
    "    node_mask_type=None,\n",
    "    edge_mask_type='object',\n",
    "    model_config=dict(\n",
    "        mode='binary_classification',\n",
    "        task_level='graph',\n",
    "        return_type='probs',\n",
    "    ),\n",
    "    threshold_config=dict(\n",
    "        threshold_type='topk',\n",
    "        value=20\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "pgexplainer = Explainer(\n",
    "    model=model,\n",
    "    algorithm=PGExplainer(epochs=200),\n",
    "    explanation_type='phenomenon',\n",
    "    node_mask_type=None,\n",
    "    edge_mask_type='object',\n",
    "    model_config=dict(\n",
    "        mode='binary_classification',\n",
    "        task_level='graph',\n",
    "        return_type='probs',\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "dummyexplainer = Explainer(\n",
    "    model=model,\n",
    "    algorithm=DummyExplainer(),\n",
    "    explanation_type='phenomenon',\n",
    "    node_mask_type=None,\n",
    "    edge_mask_type='object',\n",
    "    model_config=dict(\n",
    "        mode='binary_classification',\n",
    "        task_level='graph',\n",
    "        return_type='probs',\n",
    "    ),\n",
    "    threshold_config=dict(\n",
    "        threshold_type='topk',\n",
    "        value=7\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "0c77de0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNNExplainer unfaithfulness: 0.0\n",
      "DummyExplainer unfaithfulness: 0.0 \n",
      "\n",
      "\n",
      "GNNExplainer unfaithfulness: 0.9975946107879281\n",
      "DummyExplainer unfaithfulness: 0.9975946107879281 \n",
      "\n",
      "\n",
      "GNNExplainer unfaithfulness: 0.0\n",
      "DummyExplainer unfaithfulness: 0.0 \n",
      "\n",
      "\n",
      "GNNExplainer unfaithfulness: 0.9890693742781878\n",
      "DummyExplainer unfaithfulness: 0.9890693742781878 \n",
      "\n",
      "\n",
      "GNNExplainer unfaithfulness: 0.9820304363965988\n",
      "DummyExplainer unfaithfulness: 0.9820304363965988 \n",
      "\n",
      "\n",
      "GNNExplainer unfaithfulness: 0.9978763242252171\n",
      "DummyExplainer unfaithfulness: 0.9978763242252171 \n",
      "\n",
      "\n",
      "GNNExplainer unfaithfulness: 0.0\n",
      "DummyExplainer unfaithfulness: 0.0 \n",
      "\n",
      "\n",
      "GNNExplainer unfaithfulness: 0.9822787772864103\n",
      "DummyExplainer unfaithfulness: 0.9822787772864103 \n",
      "\n",
      "\n",
      "GNNExplainer unfaithfulness: 1.1920928955078125e-07\n",
      "DummyExplainer unfaithfulness: 1.1920928955078125e-07 \n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[217], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m      9\u001b[0m     target \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m---> 11\u001b[0m gnnexplanation \u001b[38;5;241m=\u001b[39m \u001b[43mgnnexplainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     12\u001b[0m gnn_unf \u001b[38;5;241m=\u001b[39m unfaithfulness(gnnexplainer, gnnexplanation)\n\u001b[1;32m     14\u001b[0m dummyexplanation \u001b[38;5;241m=\u001b[39m dummyexplainer(graph\u001b[38;5;241m.\u001b[39mx, graph\u001b[38;5;241m.\u001b[39medge_index, target\u001b[38;5;241m=\u001b[39mtarget, batch\u001b[38;5;241m=\u001b[39mbatch)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch_geometric/explain/explainer.py:198\u001b[0m, in \u001b[0;36mExplainer.__call__\u001b[0;34m(self, x, edge_index, target, index, **kwargs)\u001b[0m\n\u001b[1;32m    195\u001b[0m training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtraining\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m--> 198\u001b[0m explanation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malgorithm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain(training)\n\u001b[1;32m    209\u001b[0m \u001b[38;5;66;03m# Add explainer objectives to the `Explanation` object:\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch_geometric/explain/algorithm/gnn_explainer.py:75\u001b[0m, in \u001b[0;36mGNNExplainer.forward\u001b[0;34m(self, model, x, edge_index, target, index, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(edge_index, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHeterogeneous graphs not yet supported in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     73\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 75\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m node_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post_process_mask(\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_mask,\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhard_node_mask,\n\u001b[1;32m     80\u001b[0m     apply_sigmoid\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     81\u001b[0m )\n\u001b[1;32m     82\u001b[0m edge_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post_process_mask(\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medge_mask,\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhard_edge_mask,\n\u001b[1;32m     85\u001b[0m     apply_sigmoid\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     86\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch_geometric/explain/algorithm/gnn_explainer.py:127\u001b[0m, in \u001b[0;36mGNNExplainer._train\u001b[0;34m(self, model, x, edge_index, target, index, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m     y_hat, y \u001b[38;5;241m=\u001b[39m y_hat[index], y[index]\n\u001b[1;32m    125\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loss(y_hat, y)\n\u001b[0;32m--> 127\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m# In the first iteration, we collect the nodes and edges that are\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m# involved into making the prediction. These are all the nodes and\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m# edges with gradient != 0 (without regularization applied).\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gnnexplainer_Unfaithfulness = []\n",
    "dummyepxplainer_Unfaithfulness = []\n",
    "for graph in dataset: \n",
    "    \n",
    "    batch = torch.zeros(len(graph.x), dtype = int)\n",
    "    if graph.y == 1:\n",
    "        target = torch.tensor([0,1])\n",
    "    else:\n",
    "        target = torch.tensor([1,0])\n",
    "        \n",
    "    gnnexplanation = gnnexplainer(graph.x, graph.edge_index, target=target, batch=batch) \n",
    "    gnn_unf = unfaithfulness(gnnexplainer, gnnexplanation)\n",
    "    \n",
    "    dummyexplanation = dummyexplainer(graph.x, graph.edge_index, target=target, batch=batch)\n",
    "    dummy_unf = unfaithfulness(dummyexplainer, dummyexplanation)\n",
    "    \n",
    "    gnnexplainer_Unfaithfulness.append(gnn_unf)\n",
    "    dummyepxplainer_Unfaithfulness.append(dummy_unf)\n",
    "    \n",
    "    print(f\"GNNExplainer unfaithfulness: {gnn_unf}\")\n",
    "    print(f\"DummyExplainer unfaithfulness: {dummy_unf} \\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a1f2ec3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 42], x=[19, 7], edge_attr=[42, 4], y=[1])\n",
      "Actual label: 1 vs Predicted label: tensor([[-0.6901,  0.5603]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "all elements of input should be between 0 and 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[81], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m graph \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(graph)\n\u001b[0;32m---> 20\u001b[0m \u001b[43mvisualize_gnnexplainer_explanation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[81], line 6\u001b[0m, in \u001b[0;36mvisualize_gnnexplainer_explanation\u001b[0;34m(graph)\u001b[0m\n\u001b[1;32m      2\u001b[0m prediction \u001b[38;5;241m=\u001b[39m model(graph\u001b[38;5;241m.\u001b[39mx, graph\u001b[38;5;241m.\u001b[39medge_index, batch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mlen\u001b[39m(graph\u001b[38;5;241m.\u001b[39mx), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m))\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mActual label: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgraph\u001b[38;5;241m.\u001b[39my\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m vs Predicted label: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprediction\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m explanation \u001b[38;5;241m=\u001b[39m \u001b[43mgnnexplainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m graph \u001b[38;5;241m=\u001b[39m to_networkx(graph)\n\u001b[1;32m      8\u001b[0m graph \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39mcopy()\u001b[38;5;241m.\u001b[39mto_undirected()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch_geometric/explain/explainer.py:198\u001b[0m, in \u001b[0;36mExplainer.__call__\u001b[0;34m(self, x, edge_index, target, index, **kwargs)\u001b[0m\n\u001b[1;32m    195\u001b[0m training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtraining\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m--> 198\u001b[0m explanation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malgorithm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain(training)\n\u001b[1;32m    209\u001b[0m \u001b[38;5;66;03m# Add explainer objectives to the `Explanation` object:\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch_geometric/explain/algorithm/gnn_explainer.py:75\u001b[0m, in \u001b[0;36mGNNExplainer.forward\u001b[0;34m(self, model, x, edge_index, target, index, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(edge_index, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHeterogeneous graphs not yet supported in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     73\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 75\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m node_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post_process_mask(\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_mask,\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhard_node_mask,\n\u001b[1;32m     80\u001b[0m     apply_sigmoid\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     81\u001b[0m )\n\u001b[1;32m     82\u001b[0m edge_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post_process_mask(\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medge_mask,\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhard_edge_mask,\n\u001b[1;32m     85\u001b[0m     apply_sigmoid\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     86\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch_geometric/explain/algorithm/gnn_explainer.py:125\u001b[0m, in \u001b[0;36mGNNExplainer._train\u001b[0;34m(self, model, x, edge_index, target, index, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    123\u001b[0m     y_hat, y \u001b[38;5;241m=\u001b[39m y_hat[index], y[index]\n\u001b[0;32m--> 125\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_hat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    128\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch_geometric/explain/algorithm/gnn_explainer.py:167\u001b[0m, in \u001b[0;36mGNNExplainer._loss\u001b[0;34m(self, y_hat, y)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_loss\u001b[39m(\u001b[38;5;28mself\u001b[39m, y_hat: Tensor, y: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_config\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m ModelMode\u001b[38;5;241m.\u001b[39mbinary_classification:\n\u001b[0;32m--> 167\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_loss_binary_classification\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_hat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_config\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m ModelMode\u001b[38;5;241m.\u001b[39mmulticlass_classification:\n\u001b[1;32m    169\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loss_multiclass_classification(y_hat, y)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch_geometric/explain/algorithm/base.py:168\u001b[0m, in \u001b[0;36mExplainerAlgorithm._loss_binary_classification\u001b[0;34m(self, y_hat, y)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_hat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview_as\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/functional.py:3098\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3095\u001b[0m     new_size \u001b[38;5;241m=\u001b[39m _infer_size(target\u001b[38;5;241m.\u001b[39msize(), weight\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m   3096\u001b[0m     weight \u001b[38;5;241m=\u001b[39m weight\u001b[38;5;241m.\u001b[39mexpand(new_size)\n\u001b[0;32m-> 3098\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction_enum\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: all elements of input should be between 0 and 1"
     ]
    }
   ],
   "source": [
    "def visualize_gnnexplainer_explanation(graph):      \n",
    "    prediction = model(graph.x, graph.edge_index, batch = torch.zeros(len(graph.x), dtype=int))\n",
    "    \n",
    "    print(f\"Actual label: {graph.y.item()} vs Predicted label: {prediction}\")\n",
    "\n",
    "    explanation = gnnexplainer(graph.x, graph.edge_index, batch = torch.zeros(len(dataset[10].x), dtype=int))\n",
    "    graph = to_networkx(graph)\n",
    "    graph = graph.copy().to_undirected()\n",
    "\n",
    "    pos = nx.kamada_kawai_layout(graph)\n",
    "\n",
    "\n",
    "    widths = [3 if x > 0 else 1 for x in explanation.edge_mask]\n",
    "    edge_color = [(1,0,0) if x > 0 else (0,0,0) for x in explanation.edge_mask]\n",
    "    nx.draw_networkx(graph, pos=pos)\n",
    "    nx.draw_networkx_edges(graph, pos=pos, width=widths, edge_color=edge_color)\n",
    "\n",
    "graph = dataset[0]\n",
    "print(graph)\n",
    "visualize_gnnexplainer_explanation(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabb6703",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
